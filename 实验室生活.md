# 22.2.24

## 常见的数据分析应用

* TPC-DS
* CloudSort
* Big Data benchmark

# 22.2.25

## TPC

* 事务处理性能委员会，制定计算机事务处理能力测试标准并监督其执行

## TPC-DC

* 搞清楚几张表

# 22.2.27

## Pareto-optimal   

* 是指[资源分配](https://baike.baidu.com/item/资源分配/2944359)的一种理想状态，假定固有的一群人和可分配的资源，从一种分配状态到另一种状态的变化中，在没有使任何人境况变坏的前提下，使得至少一个人变得更好，这就是帕累托改进或帕累托最优化，**帕累托最优状态就是不可能再有更多的[帕累托改进](https://baike.baidu.com/item/帕累托改进/9595186)的余地**

## MapReduce

* 分布式计算模型

# 22.2.28

## PPT

* 第一页：Serverless
  * 存算分离
  * 高弹性、细粒度收费
* 第二页：Data analytics
  * 特征：多Stage、stage间有shuffle操作
  * 通过remote storage exchange intermediate data，导致较高的I/O时延
  * ![image-20220228144500774](C:\Users\asus\Desktop\image-20220228144500774.png)
  * 应用：Mapreduce sort、TPC-DS query

* 第三页：Idea
  * 明确stage间和stage内的函数对数据共享需求的差别

## PyWren Occupy the Cloud: Distributed Computing for the 99%  

* S3的网络带宽不是瓶颈，IOPS是瓶颈
* IOPS、带宽、latency对应用影响的权重

# 22.3.1

## Serverless数据分析类应用的I/O时延问题研究

* 这里的I/O时延是端到端的时延，包括传输时延和读写时延，即网络IO和磁盘IO

### S3、ElastiCache latency 网络时延

  * 100 measurements are carried out using the setupshown in Fig. 3. X-Ray is used for timing the measurements
    that first write random string data to the same key (step 1 )and then immediately read the data back (step 2 ).  

    <img src="C:\Users\asus\AppData\Roaming\Typora\typora-user-images\image-20220301155946289.png" alt="image-20220301155946289" style="zoom:67%;" />

  * ![image-20220301160021118](C:\Users\asus\AppData\Roaming\Typora\typora-user-images\image-20220301160021118.png)

### S3、ElastiCache network /网络带宽

* the gap between network bandwidth and storage I/O bandwidth is narrowing  

  <img src="C:\Users\asus\AppData\Roaming\Typora\typora-user-images\image-20220301160844877.png" alt="image-20220301160844877" style="zoom:67%;" />

### S3、ElastiCache request throughput (IOPS)

* ![image-20220301163938617](C:\Users\asus\AppData\Roaming\Typora\typora-user-images\image-20220301163938617.png)



## CaaS vs FaaS

* K8s和Serverless的区别是什么？
  * CaaS
    * The first one enables users to run application components in highly customizable containers but thus makes configuration harder  
  * FaaS
    * FaaS tries to solve the configuration issue by providing fixed execution environments where small, stateless functions could be run  

# 22.3.2

* AWS serverless 完整的技术栈：https://medium.com/serverless-transformation/what-a-typical-100-serverless-architecture-looks-like-in-aws-40f252cd0ecb

# 22.3.3

## pywren

* 是不是已经做了这样的存储优化？？？？？？

# 22.3.8

## Spark怎么处理中间数据？

## AWS lambda怎么处理中间数据？

## 几篇文章

* pywren
* numpywren
* wukong
* pocket(两篇)

## Understanding Ephemeral Storage for Serverless Analytics  

* In traditional analytics frameworks (e.g., Spark, Hadoop), ==tasks buffer intermediate data in local storage and exchange data between tasks directly== over the network  

* serverless computing frameworks achieve high elasticity and scalability by requiring tasks to be stateless [15].In other words, ==a task’s local file system and child processes are limited to the lifetime of the task itself==

* ==since serverless platforms do not expose control over task scheduling and placement, direct communication between tasks is difficult==  

* the natural approach for inter-task communication is to store intermediate data in a common, remote storage service  

* **Three different serverless analytics applications** 

  * Parallel software build ：
    * Each lambda fetches its dependencies from ephemeral storage
    * computes (i.e., compiles, archives or links depending on the stage)
    * and writes an output file  
  * MapReduce Sort ：
    * Map lambdas fetch input files from long-termstorage (S3) and write intermediate files to ephemeralstorage. 
    * Reduce lambdas merge and sort intermediate data read from ephemeral storage and write output files to S3  
    * Sorting is I/O-intensive  
    * ==Each intermediate file is written and read only once== and its size is directly proportional to the dataset size and inversely related to the number of workers  
  * Video analytics ：
    * **decode stage**：first stage lambdas read a batch of encoded video frames from ephemeral storage and write back decoded video frames 
    *  **MXNET classification stage**：Each lambda then launches a second stage lambda which reads a set of decoded frames from ephemeral storage, computes a MXNET deep learning classification algorithm and outputs a classification result  

* **Three different storage systems for ephemeral data sharing**

  * <img src="C:\Users\taoli\AppData\Roaming\Typora\typora-user-images\image-20220308163825575.png" alt="image-20220308163825575" style="zoom: 67%;" />
  * <img src="C:\Users\taoli\AppData\Roaming\Typora\typora-user-images\image-20220308163908002.png" alt="image-20220308163908002" style="zoom:67%;" />

  * S3
    * S3 has significant overhead, particularly for small requests  
  * Elasticache Redis  
    * Redis latency is ∼240 ms, two orders of magnitude lower than S3 latency  
  * Crail-ReFlex: 
    * Flash offers a medium ground between disk and DRAM for both performance and cost  

* latency sensitivity, parallelism, and I/O intensity  
  * Latency-sensitive jobs: 
    * We find that jobs in which lambdas mostly issue fine-grain I/O operations are latency-sensitive ;
    * gg shows some sensitivity to storage latency since the majority of files accessed are under 100 KB  
    * The job benefits from the lower latency of Redis storage compared to S3 with up to 100 concurrent lambdas  
  * Jobs with limited parallelism  
  * Throughput-intensive jobs  
* ==Desired ephemeral storage properties==
  * high elasticity ：To meet the I/O demands of serverless applications, which can consist of thousands of lambdas in one execution stage and
    only a few lambdas in another  
  * high IOPS and high throughput ：Since the granularity of data access varies widely (Figure 2), storing both small and large objects should be cost and performance efficient  
  * auto-scale resources  ：To relieve users from the difficulty of managing storage clusters, the storage service  

# 22.3.9

## unloaded latency & loaded latency

* Unloaded latency **measures the round-trip time of a request when there is no other traffic present on a user's network**, 
* while loaded latency measures the round-trip time when data-heavy applications are being used on the network. For example, let's say you're playing a game online on your computer

# 22.3.14

## 边缘计算 vs 云计算

## AWS limitation

* The default limit for concurrent executions is a maximum of 1000 lambdas, 512MB of temporary storage and 900 seconds of timeout

## 为什么S3对于小文件的读写不支持高吞吐率

* In fact, all major public cloud providers impose a global transaction limit on shared object stores [37, 7, 20]. This should come as no surprise, as starting with the Google File System [21], the majority of large scale storage systems have been optimized for reading and writing large chunks of data, rather than for high-throughput fine-grained operations ==Locus==
* While S3 does provide abundant I/O bandwidth to Lambda for this case, it is not designed to sustain high request rate for small objects. Also as S3 is a multi-tenant service, there is an imposed limit on request throughput per S3 bucket for the benefit of overall availability ==Pywren==  

## 典型的数据分析应用的I/O size到底会不会导致S3的I/O吞吐率成为瓶颈？

* 首先要得到数据分析应用的I/O size的分布函数图(CDF)
* 然后获得redis/S3的聚合带宽和I/O size的关系图
* 判断数据分析应用的I/O size有多大的规模落在S3 I/O throughput的瓶颈区 



# 22.3.23

## S3的适用场景

* S3 is usually meant for storing small number of large sized objects which are infrequently accessed and the latency is not that of significant importance. For instance,
  1. You store log files once every few minutes or hours
  2. Log file size are on the order of several hundred MB's or couple of GB's
  3. Read them few hundreds times
  4. Latency of even around couple of seconds is acceptable
