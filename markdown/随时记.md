# 相关问题

* severless导致大量突发并行应用的出现
* 突发并行导致overlay网络启动成为serverless 函数冷启动的主要开销
* 网络启动的开销
  * 控制平面&数据平面
  * 数据平面的步骤

# 周末安排

* 周五
  * 刷鞋、洗衣服、擦桌子
  * 打电话
* 周六
  * 上午
    * web作业 计算题
    * 勇士vs公牛
  * 下午
    * 预约医生
    * web 作业 问答题
  * 晚上
    * 制定计划
    * 总结一下没干的事
* 周日
  * 上午
    * ..看医生
  * 下午
    * 耳鼻喉

# 待做事宜

## 身体

* 体重
* 耳朵
* 胃

## 课程

* web 作业二、实验二
* 嵌入式 实验二

## 学习

* 英语六级
* 入党
* 技术栈

## 实验室

* serverless PPT
* 论文



# Catalyzer

* 高级语言应用启动时的开销和拉取镜像引入的开销区别在哪？是不是gVisor把container拉取镜像的开销转移到了应用初始化？？？
* 搞清楚现实世界中应用启动时间长的应用的占比？
* function image vs container image？

# Catalyzer

## What？

* **总结：**Catalyzer采用**持久化方案**，从结构良好的**检查点镜像恢复**基于虚拟化的函数实例，从而跳过关键路径上的初始化(init-less)，并且通过**按需恢复和重用**，优化恢复过程。

## Why？

### 问题

* 大多数高级语言serverless函数的启动延迟来自应用程序初始化，但目前没有方案关注于这一点。
* 容器隔离性差，虚拟机笨重启动开销大，采用新的轻量级虚拟方案

### 现存方案

* 基于缓存的优化

  * 方案：缓存...

  * 问题：函数很多，内存开销；无法解决尾延迟；沙箱初始化依赖函数特定的配置

* 优化沙箱启动

  * 方案：定制客户内核、定制管理程序
  * 问题：不能减轻像JVM或Python解释器那样的应用程序初始化延迟

* checkpoint/restore

  * 方案
  * 问题

## How？

* 采用checkpoint/restore的方案，并优化restore的开销
  * 执行阶段的无服务器函数通常只访问初始化阶段使用的一小部分内存和文件，因此我们可以**按需恢复**应用程序状态和系统状态    **for cold boot&warm boot**
  * 同一个函数的沙箱实例拥有几乎相同的初始化状态，因此可以**重用运行沙箱的大部分状态（沙箱模板）**来生成新的沙箱  **for fork boot**



# 嵌入式实验

./arm-2014.05/bin/arm-none-linux-gnueabi-objdump

./arm-2014.05/bin/arm-none-linux-gnueabi-readelf

./arm-2014.05/bin/arm-none-linux-gnueabi-gcc

\sum_{v\in V(D)}\sum_{e\in \alpha(v)}f(e) = \sum_{v\in V(D)}\sum_{e\in \beta(v)}f(e) \\
\sum_{v\in V(D)}\sum_{e\in \alpha(v)}f(e)  = \sum_{e\in\alpha(s)}f(e) + \sum_{e\in\alpha(t)}f(e)+\sum_{v\in V(D)-s-t}\sum_{e\in \alpha(v)}f(e) \\
\sum_{v\in V(D)}\sum_{e\in \beta(v)}f(e)  = \sum_{e\in\beta(s)}f(e) + \sum_{e\in\beta(t)}f(e)+\sum_{v\in V(D)-s-t}\sum_{e\in \beta(v)}f(e) \\



.text 

.global asm_strsort 

asm_strsort: 

STMED SP!, {V1-V8} 

mov V1, #0 @ V1 = i, number of strings, init V1 = n 

add V1, V1, R1, LSL #2 

bubble_1: 

cmp V1, #4 

bls back 

sub V1, V1, #4 

mov V2, #0 @ V2 = j, internel loop 

b bubble_2 

bubble_2: 

cmp V2, V1 

bhs bubble_1 

ldr V3, [R0, V2] @ V3 = str_list[j] 

add V2, V2, #4 

ldr V4, [R0, V2] @ V4 = str_list[j + 1] 

mov V5, #0 @ init char pointer 

b str_cmp 

str_cmp: 

ldrb V6, [V3, V5] @ V6 = str_list[j][k] 

ldrb V7, [V4, V5] @ V7 = str_list[j + 1][k] 

cmp V6, V7 @ if str_list[j][k] > str_list[j + 1][k], swap 

string

bgt swap 

cmp V6, #0 @ if str_list[j][k] == '\0', return 

beq bubble_2 

cmp V7, #0 @ if str_list[j + 1][k] == '\0', return 

beq bubble_2 

add V5, V5, #1 @ k++ 

cmp V6, V7 

beq str_cmp 

b bubble_2 

swap:

sub V8, V2, #4 @ V8 = j 

str V3, [R0, V2] 

str V4, [R0, V8] 

b bubble_2 

back:

LDMED SP!, {V1-V8} 

mov pc, lr 

.end

# SOSP’21 Serverless&StartNic track

## 问题

* serverless应用有哪些？有状态？无状态
  * serverless函数的无状态是什么意思？
  * stateless function vs stateful application？
  * 应用的状态包含什么？
  * serveless应用有哪些？
  * serverless应用的分类？有状态/无状态？或者有其他分类标准
* serverless计算特征
  * 函数量
  * 并发度
  * 重复度（迭代情况）
  * 在时空上的分布特征，有无突发
* StartNIC的用处，如何用？
* 在虚拟化k8s/serverless场景下：dcn和服务性能之间的关系
  * 网络带宽
  * 时延
  * 吞吐量

## 安排

* sosp‘21 serverless&startnic track introduction&background&motivation
  * 周六 serverless
  * 周日 startnic

## serverless application

* 视频处理
  * SoCC'18 Sprocket：并行视频处理，如编码压缩，高并发、低延迟、低成本
  * MapReduce、Hadoop、Spark
  * 微服务micro service vs serverless
  * serverless最初的目的是为了处理Web微服务和事件处理程序
  
* 数据分析

  * 问题：

    * shuffle？？

    * 什么是事务驱动的workload？？

  * NSDI'19 Locus：使用fast but expensive和cheap but slow的存储结合存储中间数据

    * 分布式计算：TPC-DS，Daytona Cloudsort，Big Data Benchmark
    * serverless适用于**高并发**、**突发**、**资源需求变化大**等弹性应用
      * 每个阶段的不同核上的任务完成速度不一样，造成一些core 空转
      * 不同阶段需求的资源需求变化大（data analysis、ML）
    * 暂时的、无状态的计算单元没有本地存储，需要将中间计算数据持久化在共享存储系统上

* 机器学习

  * serverless的无状态特性，使得必须在外部维护状态，如Amazon S3
  * SoCC’19 Cirrus：机器学习任务通常会有资源过度分配的问题
    * 在Serverless平台部署机器学习任务的挑战
    * small local memory and storage
    * Low bandwidth and lack of P2P communication，**AWS Lambdas 不允许点对点通信**？？
    * Short-lived and unpredictable launch times  
    * Lack of fast shared storage  
  
* 事务工作流

  * 

# Typora 序列号

* JD9UBB-8YAY8M-KNSU7X-X6BR5E

# Serveless Computing

* 可见,Serverless在短时运行处理(小程序后端、Web后端等)、事件驱动处理(实时图片处理、实时数据流处理等)、显著波峰波谷处理(视频转码/直播、AI推理等)各类场景均有广泛应用,可实现不同程度的降本提质增效
* In the first generation of FaaS platforms, due to the ephemeral nature of the platforms and short lived nature of the serverless functions, a push towards using FaaS only for stateless applications gained traction. More importantly, early FaaS platforms required developers to understand the operations if they had to use any kind of data store. But, the trend is [slowly changing](https://talkingserverless.com/2020/05/19/does-serverless-need-devops/) with a rethink on how data store is bundled with compute. As these newer generations of FaaS offerings mature, we can expect to see more stateful applications deployed on FaaS
* A Stateful application saves data about each client session and uses that data the next time the client makes a request whereas Stateless app is an application program that does not save client data generated in one session for use in the next session with that client

## Stateless vs Stateful

<img src="https://miro.medium.com/max/788/1*IoFCbOzsSjGOBXHUqdtpIQ.png" alt="img" style="zoom:80%;" />

* **REST APIs**
  
* stateless
  
  * A **Stateless application** or process is something that does not save or reference information about previous operations. Every time it carries each operation from the scratch just like the first time and provides functionality to use print, CDN (Content Delivery Network) or the Web Servers in order to process every short-term request
  * While Stateless applications work in different ways, they don’t store any state on the server. They use DB to store all the info. DB is stateful, i.e., it has persistent storage attached to it
  * Every request is independent and doesn’t have any link with previous or next requests, just like REST
  * You can simply scale a stateless application by deploying it on multiple servers. Scales beautifully horizontally
  * No need to bind the client to the server as in each request the client provides all its information necessary for the server to act upon it
  * **注重吞吐率，时延高，但是水平扩展性能高，状态保存在客户端，*Each request from client to server must contain all of the information necessary to understand the request, and cannot take advantage of any stored context on the server. Session state is therefore kept entirely on the client***
  * ==What is stateless Apps：==**With stateless systems, the state does not disappear. It just gets externalized into the clients and/or databases that the stateless app interacts with. In this respect, stateless apps require more sophisticated clients that cache their own state information, which provides the context for subsequent transactions. Now, stateless apps and their clients interact with greater independence**
  *  ==Stateless Apps Advantages==**[1]Visibility is improved because a monitoring system does not have to look beyond a single request datum in order to determine the full nature of the request.[2] Reliability is improved because it eases the task of recovering from partial failures.[3]Scalability is improved because not having to store state between requests allows the server component to quickly free resources, and further simplifies implementation because the server doesn’t have to manage resource usage across requests**
  
* stateful
  * A **Stateful application** remembers specific details of a user like profile, preferences, and user actions. This information is considered as the ‘Status’ of a system
  
  * They’re performed with the context of previous transactions and the current transaction may be affected by what happened during previous transactions. For these reasons, stateful apps use the same servers each time they process a request from a user
  
  * **时延低，但是收缩性差，状态保存在服务端？？**
  
  * 虽然无状态应用程序会减慢某些类型的客户端交互，但它们提供了几乎无限的可伸缩性（While stateless apps can slow down certain types of client interactions, they offer virtually infinite scalability）
  
  * ==What is Stateful Apps：==**Stateful systems use databases like any application, but they also maintain “state data” (related to client authentication and past requests) on the server itself. This makes stateful apps fast and it allows clients to interact with the application within the historical context of previous interactions**
  
  * ==Stateful Apps limitations：==**Stateful apps bind clients and users to the same server so it can process subsequent requests in the context of previous ones. Stateful systems work best under predictable workloads that the system can manage. If traffic grows, you can’t simply replicate a stateful app and redirect new client requests because users will need to start from scratch. This makes stateful apps difficult to scale and prone to system unavailability when client traffic increases**
  
  * *The disadvantages are that it reduces scalability of the server, due to the stored application state, and reduces visibility of interactions, since a monitor would have to know the complete state of the server*
  
    

## Stateless use cases

* **Trigger-based tasks**
* **Building RESTful APIs**
* **Asynchronous processing**
* **image and video processing**
* **Stream and batch processing**
* Security checks
* Continuous Integration (CI) and Continuous Delivery (CD)
* According to the CNCF, the top 10 serverless examples include:
  1. Multimedia processing: The implementation of functions that execute a transformational process in response to a file upload
  2. Database changes or change data capture: auditing or ensuring changes meet quality standards
  3. IoT sensor input messages: The ability to respond to messages and scale in response
  4. Stream processing at scale: processing data within a potentially infinite stream of messages
  5. Chat bots: scaling automatically for peak demands
  6. Batch jobs scheduled tasks: Jobs that require intense parallel computation, IO or network access
  7. HTTP REST APIs and web apps: traditional request and response workloads
  8. Mobile back ends: ability to build on the REST API backend workload above the BaaS APIs
  9. Business logic: The orchestration of microservice workloads that execute a series of steps
  10. Continuous integration pipeline: The ability to remove the need for pre-provisioned hosts
* 

# serverless 各种应用的总结

* Boki
* Faasm

# serverless app

## video processing

* Excamera
  * AWS Lambda is a microservice framework designed to execute user-supplied Lambda functions in response to
    asynchronous events, e.g., message arrivals, file uploads, or API calls made via HTTP requests  
  * workers are much less expensive for massively parallel computations that are short and infrequent  

## data analytics

* pywren
  * the functions are stateless as all the state for the function, including input, output is accessed from shared remote storage  
  * PyWren helps users avoid the significant developer and management overhead  
  * However, we do identify storage throughput as a major bottleneck for larger shuffles  

* locus
  * resource limits make it challenging to implement such applications as they need to move large amounts of data between functions that don’t overlap in time  
  * the bandwidth available between functions and the shared storage system is comparable to the disk bandwidths   
  * A direct approach to implementing shuffles would be to
    open connections between serverless workers [18] and transfer data directly between them. However, there are two limitations that prevent this approach. First cloud providers do
    not provide any guarantees on when functions are executed
    and hence the sender and receiver workers might not be executing at the same time. Second, even if the sender and
    receiver overlap, given the execution time limit, there might
    not be enough time to transfer all the necessary data.
    A natural approach to transferring data between ephemeral
    workers is to store intermediate data in a persistent storage
    system. We illustrate challenges for this approach with a
    distributed sorting example  

## ML

* Cirrus
  * uting for ML hinge on
    the ability to run ML algorithms efciently. The main challenge in
    leveraging serverless computing is the signifcantly small local resource constraints (memory, cpu, storage, network) associated with
    lambda functions, which is fundamental to serverless computation
    because the fne-granularity of computation units enables scalability and ﬂexibility  

## microservice

* nightcore
  * Serverless cloud computing enables a new way of building microservice-based applications [10, 18, 44, 52], having the beneft of
    greatly reduced operational complexity   .
  * These functions provide a natural substrate
    for implementing stateless RPC handlers in microservices, as an
    alternative to containerized RPC servers  
  * However, readily available
    FaaS systems have invocation latency overheads ranging from a few
    to tens of milliseconds [14, 55, 84] (see Table 1), making them a poor
    choice for latency-sensitive interactive microservices  
  * The microservice architecture
    also implies a high invocation rate for FaaS systems, creating a performance challenge  

# Locus - data analytics

## background

* there is a shift to using serverless computing, where **storage and compute is separated for both resource provisioning and billing**  
* Compared to virtual machines, this model provides more **fine-grained elasticity with sub-second start-up times**  
* As of now, these functions are subject to stringent **resource limits**.  **Towards ease of deployment and flexible resource allocation  **
  * AWS Lambda currently imposes a 5 minute limit on function duration and 3GB memory limit. 
  * Functions are also assumed to be stateless and are only allocated 512MB of ephemeral storage  

## motivation

* We observe that the fine-grained elasticity of serverless is key to achieve **high utilization for general computations** such as analytics workloads  
  * Whthin a stage：BSP
  * Across stages：TPC-DS query 95  

## challenge

### ==shuffle== 

* resource limits make it challenging to implement such applications as they need to **move large amounts of data between functions that don’t overlap in time**  

* main reason for the slowdown comes from **slow data shuffle between asynchronous function invocations**.  

* As the ephemeral, stateless compute units lack any local storage, and as direct transfers between functions is not always feasible, **intermediate data between stages needs to be persisted on shared storage systems like Amazon S3**

### data analytics on serverless

* Within a stage：==not bottleneck==

  * read & write

    * functions are not co-located with the storage, hence there is no data locality in this model  

    * the bandwidth available between functions and the shared storage system is comparable to the disk bandwidths  

      Disk-locality in datacenter computing considered irrelevant  hotOS’11

  * compute

    * almost linear scaling of serverless compute is ideal for supporting embarrassingly parallel workloads   

* Across stages：

  * ==shuffle：generate large number of intermediate data==
    * directly connect：
      * sender and receiver don‘t overlap
      * execution time limitation
    * use shared storage
  * broadcast

  ### Cloud storage system

* characteristics：latency、throughput、storage capacity、elasticity
* Slow storage
  * All the popular cloud providers offer support for scalable and elastic blob storage：Amazon S3, Google Cloud Storage, Azure Blob Store  
  * these storage systems are not designed to support high throughput on reading and writing small files  
  * the majority of large scale storage systems have been optimized for reading and writing large chunks of data, rather than for high-throughput fine-grained operations  
* Fast storage
  * Examples of faster storage are inmemory storage systems backed by Memcached or Redis  

### Storage Chracteristics

*  ==read & write **Throughput**   requests/sec IOPS==  ；==**bandwith**  bytes/sec==
* ==并行度和工作内存大小会影响storage的带宽==
* Using a large number of small workers is not always ideal as it could lead to an increase in the number of small I/O requests  
* Thus, jointly managing worker memory size and parallelism poses a challenging trade-off  
* <img src="C:\Users\asus\Documents\Tencent Files\1378520056\FileRecv\1DCA794E5A7AA730B3D7A0902407C034.png" alt="1DCA794E5A7AA730B3D7A0902407C034" style="zoom: 50%;" />

## design

* **combines (1)cheap but slow storage with (2) fast but expensive storage**, to achieve good performance while remaining cost-efficient  

* introduce a multi-round shuffle that **uses fast storage for intermediate data within a round**, and **uses slow storage to merge intermediate data across rounds**  

  <img src="C:\Users\asus\AppData\Roaming\Typora\typora-user-images\image-20211210145558391.png" alt="image-20211210145558391" style="zoom:67%;" />

* **cost-performance trade-off**  

  * <img src="C:\Users\asus\AppData\Roaming\Typora\typora-user-images\image-20211210152046348.png" alt="image-20211210152046348" style="zoom: 67%;" />

## evaluation

* TPC-DS、Cloudsort、BigData benchmark

## confusion

* map-reduce shuffle模型？
* 吞吐率和带宽的区别是什么？他们侧重点是什么？
* slow storage vs fast storage？为什么S3对大规模的小数据读写的性能不高？

# Boki - shared logs

## background

### shared logs

* A shared log oﬀers a simple abstraction: a totally ordered log that can be accessed and appended concurrently. While
  simple, a shared log can efciently support state machine replication [49], the well-understood approach for building
  fault-tolerantstatefulservices[24,55].ThesharedlogAPI also frees distributed applications from the burden of managing
  the details of fault-tolerant consensus, because the consensus protocol is hidden behind the API [22]. Providing shared
  logs to serverless functions can address the dual challenges of consistency and fault tolerance  

## motivation

* One key challenge in the current serverless paradigm is the mismatch between the **stateless nature of serverless functions**  and the **stateful applications** built with them  
* However, managing shared state using current options, e.g., cloud databases or object stores, **struggles to achieve strong consistency and fault tolerance while maintaining high performance and scalability**   
* The **sharedlog** is apopular approachfor building storage systems that can simultaneously achieve scalability,
  strong consistency, and fault tolerance  

## challenge

* Data locality is one challenge for serverless storage, because disaggregated storage is strongly preferred in the serverless
  environment  
* **consistency and fault tolerance**  

## design

* Boki separates the read and write path, where read locality is optimized with a cache on function nodes and writes are optimized with scale-out bandwidth  
* We present Boki (meaning bookkeeping in Japanese), a FaaS runtime that exports the shared log API to functions for
  **storing shared state**  

## evaluation

## confusion

# SNOIC

## background

## motivation

* **Exchanging intermediate data between serverless functions is a major challenge in serverless workflows**  
  * By design, IP addresses and port numbers of individual ls are not exposed to users, making direct point-to-point communication difficult  
  * serverless platforms provide no guarantees for the overlap in time between the executions of the
    parent (sending) and child (receiving) functions  
* Previous approaches  
  * implementing exchange operators optimized for object storage  
  * replacing disk-based object storage(e.g., S3) with memory-based storage (e.g., ElastiCache Redis), or combining different storage media (e.g., DRAM, SSD,NVMe) to match application needs  
  * **limitation**
    * these approaches still require passing data over the network multiple times, adding latency  
    * in-memory storage services are much more expensive than disk-based storage

## challenge



## design

<img src="C:\Users\asus\AppData\Roaming\Typora\typora-user-images\image-20211217085018426.png" alt="image-20211217085018426" style="zoom:50%;" />

* **VM-Storage**
  * This method saves the local state of the sending l in the VM’s storage and schedules the receiving l(s) to
    execute on the same VM. **This method leverages data locality to minimize latency, but imposes scheduling constraints**  
* **Direct-Passing**  
  * Direct-Passing **allows higher degrees of parallelism** and poses no restrictions on l placements compared
    to VM-Storage, but requires data to be sent over the network between source and destination VMs  
* **Remote-Storage**
  * This method provides high scalability with no restrictions on l placement. It also has the advantage of almost uniform data passing time with increasing fanout degrees as shown in Fig. 6 due to the high bandwidth of the storage layer. The disadvantage of RemoteStorage is having two serial data copies in the critical path — one from the source lambda to the remote storage and one from the remote storage to the destination lambda  

## evaluation

## confusion

# Lambada

## background

## motivation

* Combining the two arguments shows for which types of
  workloads serverless functions are most atractive for data analytics: **interactive queries on cold (i.e., infrequently accessed)**
  **data**  
* serverless functions come with signifcant limitations: **restricted network connectivity**, **limited running time**,
  **stateless operation with a very limited cache between invocations**, and **lack of control over the scheduling of functions**  
* In the context of data analytics, the most severe limitation of FaaS is arguably **the inability to have direct communication between function invocations**  

## challenge

## design

* For Lambada, our design goal is thus to use **solely existing serverless components**  

  * The workers communicate through diﬀerent types of shared serverless storage: the cloud storage system Amazon **S3 for large amounts of data**, the key-value store Amazon **DynamoDB for small amounts of data**, and **the message service Amazon SQS (Simple Qeuing System) for short messages**  
  * <img src="C:\Users\asus\AppData\Roaming\Typora\typora-user-images\image-20211219095630602.png" alt="image-20211219095630602" style="zoom:67%;" />

* BATCH-INVOCATION  

* CLOUD STORAGE SCAN OPERATOR  

  * Te fact that the memory size of the workers has an inﬂuence on the network bandwidth can be explained by the following: Te cloud provider allocates an amount of CPU resources
    to each function that is proportional to its memory size  

  * but we assume that it uses a credit-based trafc shaping mechanism
    to limit the network bandwidth of each function instance to
    the 90 MiB/s observed above  

    ![image-20211219162452098](C:\Users\asus\AppData\Roaming\Typora\typora-user-images\image-20211219162452098.png)

  * In order to support small reads from S3, we thus need to support several in-ﬂight requests but also avoid small reads wherever possible.  

    ![image-20211219163450396](C:\Users\asus\AppData\Roaming\Typora\typora-user-images\image-20211219163450396.png)

## evaluation

## confusion

* Amazon oﬀers a **message queue service** (Amazon SQS) and a **workﬂow service** (AWS Step Functions), whose pure pay-per-use
  pricing model makes them suitable as well  

* Parquet fles   

* ==exchange operator???==

  Te exchange operator10 was introduced with the Volcano execution model [13, 14] to encapsulate any form of data parallelism and has since then become a central building block
  for data-parallel query processing  

  

# Starling  

## background

* MANAGING DATA IN STARLING  
  * Base Table Storage  
  * Intermediate State  
    * ==S3 Properties==
      * Unfortunately, S3 requests often suﬀer from poor tail latency,  
      * S3 does not guarantee read-after-write consistency in some cases  --> Mitigating Object Visibility Latency  
      * Using S3, one-to-many communication is both inexpensive and straightforward. Producer tasks write an object to
        S3, making it visible to all readers that need it. All-to-all communication, as in a shufe, is more difcult to achieve at low cost  
    * Sharing intermediates  

## motivation

## challenge

## design

# 明天PPT

## motivation

## challenge

* lambada
  * restricted network connectivity, limited running time,stateless operation with a very limited cache between invocations, and lack of control over the scheduling of functions  
  * In the context of data analytics, the most severe limitation of FaaS is arguably the inability to have direct communication between function invocations  

## FaaS

* Previous work proposes a number of approaches, all of which involve running additional infrastructure on traditional VMs  
* ==完整的FaaS工作流程==
  * Typical FaaS oﬀerings today support a variety of languages (e.g.,Python, Java, Javascript, Go), allow programmers to register functions with the cloud provider, and enable users to declare events that trigger each function. The FaaS infrastructure monitors the triggering events, allocates a runtime for the function, executes it, and persists the results. The user is billed only for the computing resources used during function invocation.  
* Current FaaS offerings are targeted at stateless functions that do minimal I/O and communication  

## BaaS

* ==为什么选择S3？==
  * NoSQL services like DynamoDB [3] have very low latency but unacceptably high cost for large shufes  
  * Using virtual machines or a streaming system like Amazon Kinesis [6] both require users to provision capacity ahead of time and thus are not a suitable choice  
  * We also considered using queue services like Amazon SQS [10], but these limit message sizes (to 256KB in the case of SQS) and require encoding data as text, making it cumbersome and computationally costly for large shufes  

# 毕设

* <img src="C:\Users\asus\AppData\Roaming\Typora\typora-user-images\image-20220121083518501.png" alt="image-20220121083518501" style="zoom:67%;" />

<img src="C:\Users\asus\AppData\Roaming\Typora\typora-user-images\image-20220121083549230.png" alt="image-20220121083549230" style="zoom:67%;" />

* 老师想跟您明确一下，目前这种方案(上图)可以理解成(下图中)分布式缓存和直接传输一种结合吗，然后面临的问题就可以对应分成两方面：1.  如何选择缓存数据？（如何冷热识别（基于DAG图的权重？）？、缓存数据的规模？）；2.  解决VM网络带宽瓶颈问题(当不同VM上的接收函数同时获取一台VM上发送函数的输出数据，VM的网络带宽将成为瓶颈)？通过调度或其他方式

# 聚会

* 郭老师，你还是在一中对面住吗？
* 那我明天跟延凯十一点左右去接您一趟

# 毕设

* 首先有三个已有的工作

  * anna利用VM的内部存储
  * Sonic利用内部存储和直接传输做混合，应用感知
  * Locus增加外部存储
* issue

  * 讲清楚数据分析类应用部署在serverless上所面临的问题，这个问题有多严重
* idea：Stage感知

  * 已有的工作使用单一的存储资源：Locus(外部存储)、Cloudburst(内部存储)
  * 应用感知是以函数为粒度，一方面感知成本高；另一方面很多数据分析应用都是存在多个stage，==而且Stage内和Stage间对数据共享的需求是完全不一样的==
  * 讲清楚idea的与之前方案对比优势在哪里


# 离校申请

* 方老师，我这周需要回家一趟，3.11周五离校，3.13周日返校，我家现在没有疫情，返校会做核酸，希望老师审核通过一下
